TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665]
Labels:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643]
151643
<|endoftext|>
{'loss': 3.1609, 'grad_norm': 1.7865004539489746, 'learning_rate': 1.9780219780219784e-05, 'epoch': 0.08}
{'loss': 2.6723, 'grad_norm': 1.5009995698928833, 'learning_rate': 1.9551282051282052e-05, 'epoch': 0.16}
{'loss': 2.2945, 'grad_norm': 1.338626742362976, 'learning_rate': 1.9322344322344324e-05, 'epoch': 0.24}
{'loss': 1.9454, 'grad_norm': 1.5024445056915283, 'learning_rate': 1.9093406593406596e-05, 'epoch': 0.32}
{'loss': 1.5508, 'grad_norm': 1.1193211078643799, 'learning_rate': 1.8864468864468864e-05, 'epoch': 0.4}
{'loss': 1.4125, 'grad_norm': 1.5552171468734741, 'learning_rate': 1.8635531135531136e-05, 'epoch': 0.48}
{'loss': 1.2663, 'grad_norm': 1.9188750982284546, 'learning_rate': 1.8406593406593408e-05, 'epoch': 0.56}
{'loss': 1.1611, 'grad_norm': 1.2484707832336426, 'learning_rate': 1.817765567765568e-05, 'epoch': 0.64}
{'loss': 1.0762, 'grad_norm': 1.1698274612426758, 'learning_rate': 1.794871794871795e-05, 'epoch': 0.72}
{'loss': 1.0385, 'grad_norm': 1.4039356708526611, 'learning_rate': 1.771978021978022e-05, 'epoch': 0.8}
{'loss': 1.0296, 'grad_norm': 1.418027400970459, 'learning_rate': 1.749084249084249e-05, 'epoch': 0.88}
{'loss': 1.0254, 'grad_norm': 1.8066595792770386, 'learning_rate': 1.7261904761904763e-05, 'epoch': 0.96}
{'eval_loss': 0.9566259980201721, 'eval_runtime': 11.7926, 'eval_samples_per_second': 25.44, 'eval_steps_per_second': 12.72, 'epoch': 1.0}
{'loss': 0.9835, 'grad_norm': 1.3941946029663086, 'learning_rate': 1.7032967032967035e-05, 'epoch': 1.04}
{'loss': 0.9608, 'grad_norm': 1.1374982595443726, 'learning_rate': 1.6804029304029306e-05, 'epoch': 1.12}
{'loss': 0.9423, 'grad_norm': 1.275390386581421, 'learning_rate': 1.6575091575091578e-05, 'epoch': 1.2}
{'loss': 0.924, 'grad_norm': 1.1026732921600342, 'learning_rate': 1.6346153846153847e-05, 'epoch': 1.28}
{'loss': 0.9066, 'grad_norm': 1.2094683647155762, 'learning_rate': 1.6117216117216118e-05, 'epoch': 1.36}
{'loss': 0.95, 'grad_norm': 1.3595647811889648, 'learning_rate': 1.588827838827839e-05, 'epoch': 1.44}
{'loss': 0.8568, 'grad_norm': 1.422835350036621, 'learning_rate': 1.5659340659340662e-05, 'epoch': 1.52}
{'loss': 0.9181, 'grad_norm': 1.1201114654541016, 'learning_rate': 1.5430402930402934e-05, 'epoch': 1.6}
{'loss': 0.8783, 'grad_norm': 1.3194001913070679, 'learning_rate': 1.5201465201465202e-05, 'epoch': 1.68}
{'loss': 0.8927, 'grad_norm': 1.3355457782745361, 'learning_rate': 1.4972527472527474e-05, 'epoch': 1.76}
{'loss': 0.9391, 'grad_norm': 1.3353716135025024, 'learning_rate': 1.4743589743589745e-05, 'epoch': 1.84}
{'loss': 0.8986, 'grad_norm': 1.1508715152740479, 'learning_rate': 1.4514652014652015e-05, 'epoch': 1.92}
{'loss': 0.8915, 'grad_norm': 1.4721351861953735, 'learning_rate': 1.4285714285714287e-05, 'epoch': 2.0}
{'eval_loss': 0.8728182911872864, 'eval_runtime': 11.7936, 'eval_samples_per_second': 25.437, 'eval_steps_per_second': 12.719, 'epoch': 2.0}
{'loss': 0.8986, 'grad_norm': 1.0905587673187256, 'learning_rate': 1.4056776556776557e-05, 'epoch': 2.08}
{'loss': 0.8648, 'grad_norm': 1.1016411781311035, 'learning_rate': 1.3827838827838829e-05, 'epoch': 2.16}
{'loss': 0.8606, 'grad_norm': 1.1197329759597778, 'learning_rate': 1.35989010989011e-05, 'epoch': 2.24}
{'loss': 0.9057, 'grad_norm': 1.613994836807251, 'learning_rate': 1.336996336996337e-05, 'epoch': 2.32}
{'loss': 0.8601, 'grad_norm': 1.0798354148864746, 'learning_rate': 1.3141025641025642e-05, 'epoch': 2.4}
{'loss': 0.9049, 'grad_norm': 1.1174075603485107, 'learning_rate': 1.2912087912087914e-05, 'epoch': 2.48}
{'loss': 0.8819, 'grad_norm': 1.0314807891845703, 'learning_rate': 1.2683150183150184e-05, 'epoch': 2.56}
{'loss': 0.9081, 'grad_norm': 1.292523980140686, 'learning_rate': 1.2454212454212456e-05, 'epoch': 2.64}
{'loss': 0.8541, 'grad_norm': 1.0675569772720337, 'learning_rate': 1.2225274725274728e-05, 'epoch': 2.72}
{'loss': 0.8855, 'grad_norm': 1.6108229160308838, 'learning_rate': 1.1996336996336996e-05, 'epoch': 2.8}
{'loss': 0.8617, 'grad_norm': 1.4074676036834717, 'learning_rate': 1.176739926739927e-05, 'epoch': 2.88}
{'loss': 0.8326, 'grad_norm': 1.0878576040267944, 'learning_rate': 1.1538461538461538e-05, 'epoch': 2.96}
{'eval_loss': 0.8532710671424866, 'eval_runtime': 11.789, 'eval_samples_per_second': 25.448, 'eval_steps_per_second': 12.724, 'epoch': 3.0}
{'loss': 0.8599, 'grad_norm': 0.972711443901062, 'learning_rate': 1.130952380952381e-05, 'epoch': 3.04}
{'loss': 0.902, 'grad_norm': 1.153782606124878, 'learning_rate': 1.1080586080586081e-05, 'epoch': 3.12}
{'loss': 0.8823, 'grad_norm': 1.2215839624404907, 'learning_rate': 1.0851648351648351e-05, 'epoch': 3.2}
{'loss': 0.8856, 'grad_norm': 1.5283417701721191, 'learning_rate': 1.0622710622710623e-05, 'epoch': 3.28}
{'loss': 0.8052, 'grad_norm': 1.0418593883514404, 'learning_rate': 1.0393772893772895e-05, 'epoch': 3.36}
{'loss': 0.8726, 'grad_norm': 1.2136605978012085, 'learning_rate': 1.0164835164835165e-05, 'epoch': 3.44}
{'loss': 0.8323, 'grad_norm': 1.152915596961975, 'learning_rate': 9.935897435897437e-06, 'epoch': 3.52}
{'loss': 0.8843, 'grad_norm': 0.9314824938774109, 'learning_rate': 9.706959706959708e-06, 'epoch': 3.6}
{'loss': 0.8671, 'grad_norm': 1.136216163635254, 'learning_rate': 9.478021978021978e-06, 'epoch': 3.68}
{'loss': 0.8466, 'grad_norm': 1.3598754405975342, 'learning_rate': 9.24908424908425e-06, 'epoch': 3.76}
{'loss': 0.8343, 'grad_norm': 1.060871958732605, 'learning_rate': 9.02014652014652e-06, 'epoch': 3.84}
{'loss': 0.8344, 'grad_norm': 0.9730360507965088, 'learning_rate': 8.791208791208792e-06, 'epoch': 3.92}
{'loss': 0.8379, 'grad_norm': 1.4365315437316895, 'learning_rate': 8.562271062271062e-06, 'epoch': 4.0}
{'eval_loss': 0.8421273827552795, 'eval_runtime': 11.7894, 'eval_samples_per_second': 25.447, 'eval_steps_per_second': 12.723, 'epoch': 4.0}
{'loss': 0.858, 'grad_norm': 1.086828351020813, 'learning_rate': 8.333333333333334e-06, 'epoch': 4.07}
{'loss': 0.8581, 'grad_norm': 1.341896891593933, 'learning_rate': 8.104395604395605e-06, 'epoch': 4.15}
{'loss': 0.8244, 'grad_norm': 1.0592858791351318, 'learning_rate': 7.875457875457876e-06, 'epoch': 4.23}
{'loss': 0.8739, 'grad_norm': 1.1660963296890259, 'learning_rate': 7.646520146520147e-06, 'epoch': 4.31}
{'loss': 0.8316, 'grad_norm': 0.9759681820869446, 'learning_rate': 7.417582417582418e-06, 'epoch': 4.39}
{'loss': 0.8574, 'grad_norm': 1.264224648475647, 'learning_rate': 7.188644688644689e-06, 'epoch': 4.47}
{'loss': 0.8654, 'grad_norm': 1.0238662958145142, 'learning_rate': 6.95970695970696e-06, 'epoch': 4.55}
{'loss': 0.8402, 'grad_norm': 0.9808943867683411, 'learning_rate': 6.730769230769232e-06, 'epoch': 4.63}
{'loss': 0.8223, 'grad_norm': 1.1291882991790771, 'learning_rate': 6.5018315018315026e-06, 'epoch': 4.71}
{'loss': 0.8671, 'grad_norm': 1.4396880865097046, 'learning_rate': 6.2728937728937735e-06, 'epoch': 4.79}
{'loss': 0.8698, 'grad_norm': 1.1013362407684326, 'learning_rate': 6.043956043956044e-06, 'epoch': 4.87}
{'loss': 0.8224, 'grad_norm': 1.079594612121582, 'learning_rate': 5.815018315018316e-06, 'epoch': 4.95}
{'eval_loss': 0.8382008075714111, 'eval_runtime': 11.7886, 'eval_samples_per_second': 25.448, 'eval_steps_per_second': 12.724, 'epoch': 5.0}
{'loss': 0.8235, 'grad_norm': 1.3112421035766602, 'learning_rate': 5.586080586080587e-06, 'epoch': 5.03}
{'loss': 0.8357, 'grad_norm': 1.2722926139831543, 'learning_rate': 5.357142857142857e-06, 'epoch': 5.11}
{'loss': 0.8381, 'grad_norm': 2.432520866394043, 'learning_rate': 5.128205128205128e-06, 'epoch': 5.19}
{'loss': 0.8588, 'grad_norm': 1.1804612874984741, 'learning_rate': 4.8992673992674e-06, 'epoch': 5.27}
{'loss': 0.8369, 'grad_norm': 1.2262086868286133, 'learning_rate': 4.6703296703296706e-06, 'epoch': 5.35}
{'loss': 0.8364, 'grad_norm': 1.3722590208053589, 'learning_rate': 4.4413919413919415e-06, 'epoch': 5.43}
{'loss': 0.8599, 'grad_norm': 0.9968483448028564, 'learning_rate': 4.212454212454213e-06, 'epoch': 5.51}
{'loss': 0.8513, 'grad_norm': 1.0797717571258545, 'learning_rate': 3.983516483516483e-06, 'epoch': 5.59}
{'loss': 0.845, 'grad_norm': 1.15570867061615, 'learning_rate': 3.754578754578755e-06, 'epoch': 5.67}
{'loss': 0.8631, 'grad_norm': 1.1689273118972778, 'learning_rate': 3.5256410256410263e-06, 'epoch': 5.75}
{'loss': 0.845, 'grad_norm': 1.0900477170944214, 'learning_rate': 3.2967032967032968e-06, 'epoch': 5.83}
{'loss': 0.8299, 'grad_norm': 1.2078464031219482, 'learning_rate': 3.067765567765568e-06, 'epoch': 5.91}
{'loss': 0.8387, 'grad_norm': 1.2978769540786743, 'learning_rate': 2.838827838827839e-06, 'epoch': 5.99}
{'eval_loss': 0.834777295589447, 'eval_runtime': 11.7897, 'eval_samples_per_second': 25.446, 'eval_steps_per_second': 12.723, 'epoch': 6.0}
{'loss': 0.8396, 'grad_norm': 1.2680296897888184, 'learning_rate': 2.6098901098901103e-06, 'epoch': 6.07}
{'loss': 0.8564, 'grad_norm': 1.5189107656478882, 'learning_rate': 2.380952380952381e-06, 'epoch': 6.15}
{'loss': 0.8876, 'grad_norm': 1.1586580276489258, 'learning_rate': 2.1520146520146525e-06, 'epoch': 6.23}
{'loss': 0.8234, 'grad_norm': 1.4534456729888916, 'learning_rate': 1.9230769230769234e-06, 'epoch': 6.31}
{'loss': 0.8087, 'grad_norm': 0.9865485429763794, 'learning_rate': 1.6941391941391943e-06, 'epoch': 6.39}
{'loss': 0.8407, 'grad_norm': 1.0460519790649414, 'learning_rate': 1.4652014652014654e-06, 'epoch': 6.47}
{'loss': 0.8357, 'grad_norm': 1.3704419136047363, 'learning_rate': 1.2362637362637365e-06, 'epoch': 6.55}
{'loss': 0.8556, 'grad_norm': 1.236399531364441, 'learning_rate': 1.0073260073260074e-06, 'epoch': 6.63}
{'loss': 0.8722, 'grad_norm': 1.0406559705734253, 'learning_rate': 7.783882783882785e-07, 'epoch': 6.71}
{'loss': 0.8336, 'grad_norm': 1.2640033960342407, 'learning_rate': 5.494505494505495e-07, 'epoch': 6.79}
{'loss': 0.7861, 'grad_norm': 1.1921162605285645, 'learning_rate': 3.205128205128205e-07, 'epoch': 6.87}
{'loss': 0.8444, 'grad_norm': 1.0993716716766357, 'learning_rate': 9.157509157509159e-08, 'epoch': 6.95}
{'eval_loss': 0.8339561820030212, 'eval_runtime': 11.7894, 'eval_samples_per_second': 25.447, 'eval_steps_per_second': 12.723, 'epoch': 6.98}
{'train_runtime': 1509.0464, 'train_samples_per_second': 11.597, 'train_steps_per_second': 1.447, 'train_loss': 0.9703380234075554, 'epoch': 6.98}
:) hope it's better now
