TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [128000, 38989, 267, 354, 552, 45576, 6987, 64519, 11906, 84, 1062, 347, 300, 48371, 3200, 66, 3251, 300, 653, 43329, 587, 9459, 3208, 25330, 336, 11, 10044, 104, 6455, 22924, 4991, 3864, 299, 45356, 13075, 281, 3978, 324, 89, 61711, 9004, 908, 11269, 73, 84309, 13046, 1662, 31757, 73678, 31757, 627, 34, 321, 85, 79083, 74, 309, 37524, 128, 115, 3978, 87272, 11427, 31757, 8747, 52314, 13247, 16, 8, 16909, 3355, 129, 228, 11906, 2145, 79, 31757, 81, 6348, 13247, 17, 8, 653, 1488, 437, 1073, 3267, 648, 503, 2784, 31757, 73, 25330, 21236, 300, 7251, 105112, 912, 513, 2749, 13247, 18, 8, 259, 31757, 37524, 285, 1488, 437, 37181, 4824, 31757, 5697, 13127, 19, 340, 7, 16, 8, 27790, 1900, 125619, 6181, 11091, 61711, 56167, 1609, 84309, 627, 7, 17, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 18, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 19, 8, 52433, 2641, 6463, 31757, 3315, 1028, 1609, 13722, 387, 343, 300, 13, 128256, 128256, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257, 128257]
Labels:  [128000, 38989, 267, 354, 552, 45576, 6987, 64519, 11906, 84, 1062, 347, 300, 48371, 3200, 66, 3251, 300, 653, 43329, 587, 9459, 3208, 25330, 336, 11, 10044, 104, 6455, 22924, 4991, 3864, 299, 45356, 13075, 281, 3978, 324, 89, 61711, 9004, 908, 11269, 73, 84309, 13046, 1662, 31757, 73678, 31757, 627, 34, 321, 85, 79083, 74, 309, 37524, 128, 115, 3978, 87272, 11427, 31757, 8747, 52314, 13247, 16, 8, 16909, 3355, 129, 228, 11906, 2145, 79, 31757, 81, 6348, 13247, 17, 8, 653, 1488, 437, 1073, 3267, 648, 503, 2784, 31757, 73, 25330, 21236, 300, 7251, 105112, 912, 513, 2749, 13247, 18, 8, 259, 31757, 37524, 285, 1488, 437, 37181, 4824, 31757, 5697, 13127, 19, 340, 7, 16, 8, 27790, 1900, 125619, 6181, 11091, 61711, 56167, 1609, 84309, 627, 7, 17, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 18, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 19, 8, 52433, 2641, 6463, 31757, 3315, 1028, 1609, 13722, 387, 343, 300, 13, 128256, 128256, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [128000, 38989, 267, 354, 552, 45576, 6987, 64519, 11906, 84, 1062, 347, 300, 48371, 3200, 66, 3251, 300, 653, 43329, 587, 9459, 3208, 25330, 336, 11, 10044, 104, 6455, 22924, 4991, 3864, 299, 45356, 13075, 281, 3978, 324, 89, 61711, 9004, 908, 11269, 73, 84309, 13046, 1662, 31757, 73678, 31757, 627, 34, 321, 85, 79083, 74, 309, 37524, 128, 115, 3978, 87272, 11427, 31757, 8747, 52314, 13247, 16, 8, 16909, 3355, 129, 228, 11906, 2145, 79, 31757, 81, 6348, 13247, 17, 8, 653, 1488, 437, 1073, 3267, 648, 503, 2784, 31757, 73, 25330, 21236, 300, 7251, 105112, 912, 513, 2749, 13247, 18, 8, 259, 31757, 37524, 285, 1488, 437, 37181, 4824, 31757, 5697, 13127, 19, 340, 7, 16, 8, 27790, 1900, 125619, 6181, 11091, 61711, 56167, 1609, 84309, 627, 7, 17, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 18, 8, 27790, 1900, 125619, 6181, 3355, 268, 75, 61711, 38977, 61711, 40625, 1028, 1609, 13722, 3067, 128, 120, 300, 627, 7, 19, 8, 52433, 2641, 6463, 31757, 3315, 1028, 1609, 13722, 387, 343, 300, 13, 128256, 128256]
128256
<|endoftext|>
{'loss': 2.6736, 'grad_norm': 2.045003890991211, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.08}
{'loss': 2.1077, 'grad_norm': 1.7427510023117065, 'learning_rate': 1.842948717948718e-05, 'epoch': 0.16}
{'loss': 1.6181, 'grad_norm': 2.039461851119995, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.24}
{'loss': 1.349, 'grad_norm': 1.476645588874817, 'learning_rate': 1.682692307692308e-05, 'epoch': 0.32}
{'loss': 1.1592, 'grad_norm': 1.369003176689148, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.4}
{'loss': 1.1221, 'grad_norm': 1.6722731590270996, 'learning_rate': 1.5224358974358975e-05, 'epoch': 0.48}
{'loss': 1.0871, 'grad_norm': 1.5793688297271729, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.56}
{'loss': 1.0698, 'grad_norm': 1.7393274307250977, 'learning_rate': 1.3621794871794874e-05, 'epoch': 0.64}
{'loss': 1.0321, 'grad_norm': 1.3487293720245361, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.72}
{'loss': 1.0341, 'grad_norm': 1.8021366596221924, 'learning_rate': 1.201923076923077e-05, 'epoch': 0.8}
{'loss': 1.032, 'grad_norm': 1.6986908912658691, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.88}
{'loss': 1.03, 'grad_norm': 1.6538997888565063, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.96}
{'eval_loss': 1.015630841255188, 'eval_runtime': 13.2376, 'eval_samples_per_second': 22.663, 'eval_steps_per_second': 11.331, 'epoch': 1.0}
{'loss': 1.0152, 'grad_norm': 1.23171865940094, 'learning_rate': 9.615384615384616e-06, 'epoch': 1.04}
{'loss': 0.9901, 'grad_norm': 1.3689537048339844, 'learning_rate': 8.814102564102565e-06, 'epoch': 1.12}
{'loss': 1.0026, 'grad_norm': 2.190817356109619, 'learning_rate': 8.012820512820515e-06, 'epoch': 1.2}
{'loss': 1.0053, 'grad_norm': 1.3950233459472656, 'learning_rate': 7.211538461538462e-06, 'epoch': 1.28}
{'loss': 0.9834, 'grad_norm': 1.7896946668624878, 'learning_rate': 6.410256410256412e-06, 'epoch': 1.36}
{'loss': 1.0281, 'grad_norm': 2.0092949867248535, 'learning_rate': 5.608974358974359e-06, 'epoch': 1.44}
{'loss': 0.9625, 'grad_norm': 1.7691988945007324, 'learning_rate': 4.807692307692308e-06, 'epoch': 1.52}
{'loss': 1.0049, 'grad_norm': 1.6521718502044678, 'learning_rate': 4.006410256410257e-06, 'epoch': 1.6}
{'loss': 0.9863, 'grad_norm': 2.1435389518737793, 'learning_rate': 3.205128205128206e-06, 'epoch': 1.68}
{'loss': 0.9895, 'grad_norm': 1.779771327972412, 'learning_rate': 2.403846153846154e-06, 'epoch': 1.76}
{'loss': 1.0257, 'grad_norm': 1.5639444589614868, 'learning_rate': 1.602564102564103e-06, 'epoch': 1.84}
{'loss': 0.995, 'grad_norm': 1.6842265129089355, 'learning_rate': 8.012820512820515e-07, 'epoch': 1.92}
{'eval_loss': 0.9949696063995361, 'eval_runtime': 13.2384, 'eval_samples_per_second': 22.661, 'eval_steps_per_second': 11.331, 'epoch': 2.0}
{'train_runtime': 477.8075, 'train_samples_per_second': 10.464, 'train_steps_per_second': 1.306, 'train_loss': 1.1722755707227266, 'epoch': 2.0}
:) hope it's better now
