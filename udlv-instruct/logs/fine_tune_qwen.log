TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665]
Labels:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643]
151643
<|endoftext|>
{'loss': 3.1677, 'grad_norm': 1.760379433631897, 'learning_rate': 1.9487179487179488e-05, 'epoch': 0.08}
{'loss': 2.6876, 'grad_norm': 1.4078364372253418, 'learning_rate': 1.8952991452991453e-05, 'epoch': 0.16}
{'loss': 2.3186, 'grad_norm': 1.3682267665863037, 'learning_rate': 1.841880341880342e-05, 'epoch': 0.24}
{'loss': 1.9905, 'grad_norm': 1.5007457733154297, 'learning_rate': 1.7884615384615387e-05, 'epoch': 0.32}
{'loss': 1.5975, 'grad_norm': 1.1576662063598633, 'learning_rate': 1.7350427350427352e-05, 'epoch': 0.4}
{'loss': 1.4454, 'grad_norm': 1.4486852884292603, 'learning_rate': 1.6816239316239317e-05, 'epoch': 0.48}
{'loss': 1.3252, 'grad_norm': 1.7093833684921265, 'learning_rate': 1.6282051282051282e-05, 'epoch': 0.56}
{'loss': 1.2181, 'grad_norm': 1.4894297122955322, 'learning_rate': 1.5747863247863247e-05, 'epoch': 0.64}
{'loss': 1.1073, 'grad_norm': 1.2314515113830566, 'learning_rate': 1.5213675213675214e-05, 'epoch': 0.72}
{'loss': 1.0595, 'grad_norm': 1.3228192329406738, 'learning_rate': 1.467948717948718e-05, 'epoch': 0.8}
{'loss': 1.0557, 'grad_norm': 1.505985975265503, 'learning_rate': 1.4145299145299148e-05, 'epoch': 0.88}
{'loss': 1.0581, 'grad_norm': 2.126645565032959, 'learning_rate': 1.3611111111111113e-05, 'epoch': 0.96}
{'eval_loss': 0.9902209639549255, 'eval_runtime': 11.7863, 'eval_samples_per_second': 25.453, 'eval_steps_per_second': 12.727, 'epoch': 1.0}
{'loss': 1.0138, 'grad_norm': 1.4067553281784058, 'learning_rate': 1.3076923076923078e-05, 'epoch': 1.04}
{'loss': 0.9936, 'grad_norm': 1.1640995740890503, 'learning_rate': 1.2542735042735043e-05, 'epoch': 1.12}
{'loss': 0.9723, 'grad_norm': 1.6527142524719238, 'learning_rate': 1.2008547008547009e-05, 'epoch': 1.2}
{'loss': 0.9485, 'grad_norm': 1.3268712759017944, 'learning_rate': 1.1474358974358974e-05, 'epoch': 1.28}
{'loss': 0.934, 'grad_norm': 1.2875202894210815, 'learning_rate': 1.0940170940170942e-05, 'epoch': 1.36}
{'loss': 0.973, 'grad_norm': 1.2140828371047974, 'learning_rate': 1.0405982905982907e-05, 'epoch': 1.44}
{'loss': 0.8826, 'grad_norm': 2.030890941619873, 'learning_rate': 9.871794871794872e-06, 'epoch': 1.52}
{'loss': 0.9433, 'grad_norm': 1.394465684890747, 'learning_rate': 9.33760683760684e-06, 'epoch': 1.6}
{'loss': 0.9022, 'grad_norm': 1.3505396842956543, 'learning_rate': 8.803418803418804e-06, 'epoch': 1.68}
{'loss': 0.9138, 'grad_norm': 1.7087222337722778, 'learning_rate': 8.26923076923077e-06, 'epoch': 1.76}
{'loss': 0.9594, 'grad_norm': 1.2026689052581787, 'learning_rate': 7.735042735042736e-06, 'epoch': 1.84}
{'loss': 0.9218, 'grad_norm': 1.2063701152801514, 'learning_rate': 7.2008547008547015e-06, 'epoch': 1.92}
{'loss': 0.9179, 'grad_norm': 1.609229326248169, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}
{'eval_loss': 0.9028436541557312, 'eval_runtime': 11.7886, 'eval_samples_per_second': 25.448, 'eval_steps_per_second': 12.724, 'epoch': 2.0}
{'loss': 0.9257, 'grad_norm': 1.1742124557495117, 'learning_rate': 6.1324786324786335e-06, 'epoch': 2.08}
{'loss': 0.8945, 'grad_norm': 1.2954351902008057, 'learning_rate': 5.598290598290599e-06, 'epoch': 2.16}
{'loss': 0.8852, 'grad_norm': 1.1925225257873535, 'learning_rate': 5.064102564102565e-06, 'epoch': 2.24}
{'loss': 0.9352, 'grad_norm': 1.6911704540252686, 'learning_rate': 4.5299145299145306e-06, 'epoch': 2.32}
{'loss': 0.8886, 'grad_norm': 1.2221344709396362, 'learning_rate': 3.9957264957264966e-06, 'epoch': 2.4}
{'loss': 0.9311, 'grad_norm': 1.0911797285079956, 'learning_rate': 3.4615384615384617e-06, 'epoch': 2.48}
{'loss': 0.9057, 'grad_norm': 1.2272893190383911, 'learning_rate': 2.9273504273504277e-06, 'epoch': 2.56}
{'loss': 0.9364, 'grad_norm': 1.4553340673446655, 'learning_rate': 2.3931623931623937e-06, 'epoch': 2.64}
{'loss': 0.8797, 'grad_norm': 1.198620319366455, 'learning_rate': 1.8589743589743592e-06, 'epoch': 2.72}
{'loss': 0.9137, 'grad_norm': 1.1846227645874023, 'learning_rate': 1.324786324786325e-06, 'epoch': 2.8}
{'loss': 0.8931, 'grad_norm': 1.586316466331482, 'learning_rate': 7.905982905982906e-07, 'epoch': 2.88}
{'loss': 0.8641, 'grad_norm': 1.4344290494918823, 'learning_rate': 2.564102564102564e-07, 'epoch': 2.96}
{'eval_loss': 0.8843818306922913, 'eval_runtime': 11.7826, 'eval_samples_per_second': 25.461, 'eval_steps_per_second': 12.731, 'epoch': 2.99}
{'train_runtime': 625.6387, 'train_samples_per_second': 11.988, 'train_steps_per_second': 1.496, 'train_loss': 1.1630031033458872, 'epoch': 2.99}
:) hope it's better now
