TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665, 151665]
Labels:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [37889, 267, 354, 550, 44476, 6844, 63419, 11645, 84, 1044, 347, 300, 47271, 3122, 66, 3172, 300, 650, 42229, 585, 9275, 3130, 24336, 336, 11, 9843, 104, 6321, 22137, 4886, 3779, 299, 44256, 12784, 281, 3891, 324, 89, 60611, 8828, 898, 11023, 73, 83209, 12756, 1630, 30657, 72578, 30657, 624, 34, 321, 85, 77983, 74, 309, 36424, 145767, 3891, 86172, 11179, 30657, 8579, 51214, 12950, 16, 8, 16502, 3275, 145910, 11645, 2098, 79, 30657, 81, 6216, 12950, 17, 8, 650, 1461, 436, 1055, 3187, 645, 502, 2717, 30657, 73, 24336, 20589, 300, 7106, 11645, 72, 902, 511, 2682, 12950, 18, 8, 259, 30657, 36424, 285, 1461, 436, 36081, 4719, 30657, 5580, 12832, 19, 340, 7, 16, 8, 26692, 1862, 518, 67, 6053, 10854, 60611, 55067, 1579, 83209, 624, 7, 17, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 18, 8, 26692, 1862, 518, 67, 6053, 3275, 268, 75, 60611, 37877, 60611, 39525, 1013, 1579, 13416, 2994, 145909, 300, 624, 7, 19, 8, 51333, 2576, 6329, 30657, 3235, 1013, 1579, 13416, 387, 343, 300, 13, 151643, 151643]
151643
<|endoftext|>
{'loss': 3.1653, 'grad_norm': 1.7880492210388184, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.08}
{'loss': 2.6892, 'grad_norm': 1.5068353414535522, 'learning_rate': 1.842948717948718e-05, 'epoch': 0.16}
{'loss': 2.3296, 'grad_norm': 1.2986268997192383, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.24}
{'loss': 2.0221, 'grad_norm': 1.587985873222351, 'learning_rate': 1.682692307692308e-05, 'epoch': 0.32}
{'loss': 1.6371, 'grad_norm': 1.199157953262329, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.4}
{'loss': 1.4735, 'grad_norm': 1.5833767652511597, 'learning_rate': 1.5224358974358975e-05, 'epoch': 0.48}
{'loss': 1.3476, 'grad_norm': 1.6043106317520142, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.56}
{'loss': 1.2632, 'grad_norm': 1.9039002656936646, 'learning_rate': 1.3621794871794874e-05, 'epoch': 0.64}
{'loss': 1.1363, 'grad_norm': 1.218139886856079, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.72}
{'loss': 1.0866, 'grad_norm': 1.2579338550567627, 'learning_rate': 1.201923076923077e-05, 'epoch': 0.8}
{'loss': 1.0811, 'grad_norm': 1.4515354633331299, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.88}
{'loss': 1.0827, 'grad_norm': 1.7068921327590942, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.96}
{'eval_loss': 1.0202624797821045, 'eval_runtime': 11.7865, 'eval_samples_per_second': 25.453, 'eval_steps_per_second': 12.726, 'epoch': 1.0}
{'loss': 1.0433, 'grad_norm': 1.8769084215164185, 'learning_rate': 9.615384615384616e-06, 'epoch': 1.04}
{'loss': 1.022, 'grad_norm': 1.1366921663284302, 'learning_rate': 8.814102564102565e-06, 'epoch': 1.12}
{'loss': 1.0093, 'grad_norm': 1.6943517923355103, 'learning_rate': 8.012820512820515e-06, 'epoch': 1.2}
{'loss': 0.9828, 'grad_norm': 1.2482808828353882, 'learning_rate': 7.211538461538462e-06, 'epoch': 1.28}
{'loss': 0.9665, 'grad_norm': 1.20252525806427, 'learning_rate': 6.410256410256412e-06, 'epoch': 1.36}
{'loss': 1.0079, 'grad_norm': 1.499979019165039, 'learning_rate': 5.608974358974359e-06, 'epoch': 1.44}
{'loss': 0.9179, 'grad_norm': 2.5064589977264404, 'learning_rate': 4.807692307692308e-06, 'epoch': 1.52}
{'loss': 0.9761, 'grad_norm': 1.321165680885315, 'learning_rate': 4.006410256410257e-06, 'epoch': 1.6}
{'loss': 0.9337, 'grad_norm': 1.272072434425354, 'learning_rate': 3.205128205128206e-06, 'epoch': 1.68}
{'loss': 0.95, 'grad_norm': 1.3654301166534424, 'learning_rate': 2.403846153846154e-06, 'epoch': 1.76}
{'loss': 0.9964, 'grad_norm': 1.4070664644241333, 'learning_rate': 1.602564102564103e-06, 'epoch': 1.84}
{'loss': 0.9557, 'grad_norm': 1.2802618741989136, 'learning_rate': 8.012820512820515e-07, 'epoch': 1.92}
{'eval_loss': 0.9402854442596436, 'eval_runtime': 11.7857, 'eval_samples_per_second': 25.455, 'eval_steps_per_second': 12.727, 'epoch': 2.0}
{'train_runtime': 430.7814, 'train_samples_per_second': 11.607, 'train_steps_per_second': 1.449, 'train_loss': 1.321638055336781, 'epoch': 2.0}
:) hope it's better now
