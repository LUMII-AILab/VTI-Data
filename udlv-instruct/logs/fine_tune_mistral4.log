TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073]
Labels:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072]
131072
<|endoftext|>
{'loss': 2.8435, 'grad_norm': 3.5969536304473877, 'learning_rate': 1.9615384615384617e-05, 'epoch': 0.08}
{'loss': 1.9343, 'grad_norm': 2.547205924987793, 'learning_rate': 1.921474358974359e-05, 'epoch': 0.16}
{'loss': 1.4561, 'grad_norm': 2.4578237533569336, 'learning_rate': 1.8814102564102566e-05, 'epoch': 0.24}
{'loss': 1.333, 'grad_norm': 2.7245049476623535, 'learning_rate': 1.841346153846154e-05, 'epoch': 0.32}
{'loss': 1.2234, 'grad_norm': 2.751840591430664, 'learning_rate': 1.8012820512820515e-05, 'epoch': 0.4}
{'loss': 1.2105, 'grad_norm': 2.9087276458740234, 'learning_rate': 1.7612179487179487e-05, 'epoch': 0.48}
{'loss': 1.1904, 'grad_norm': 2.9686310291290283, 'learning_rate': 1.7211538461538465e-05, 'epoch': 0.56}
{'loss': 1.1853, 'grad_norm': 3.328583240509033, 'learning_rate': 1.6810897435897436e-05, 'epoch': 0.64}
{'loss': 1.1475, 'grad_norm': 2.3224544525146484, 'learning_rate': 1.641025641025641e-05, 'epoch': 0.72}
{'loss': 1.1244, 'grad_norm': 2.3873491287231445, 'learning_rate': 1.6009615384615385e-05, 'epoch': 0.8}
{'loss': 1.113, 'grad_norm': 2.5783450603485107, 'learning_rate': 1.560897435897436e-05, 'epoch': 0.88}
{'loss': 1.1174, 'grad_norm': 2.693525552749634, 'learning_rate': 1.5208333333333333e-05, 'epoch': 0.96}
{'eval_loss': 1.0956895351409912, 'eval_runtime': 13.0023, 'eval_samples_per_second': 23.073, 'eval_steps_per_second': 11.536, 'epoch': 1.0}
{'loss': 1.0987, 'grad_norm': 2.339050769805908, 'learning_rate': 1.480769230769231e-05, 'epoch': 1.04}
{'loss': 1.074, 'grad_norm': 2.7042043209075928, 'learning_rate': 1.4407051282051283e-05, 'epoch': 1.12}
{'loss': 1.0792, 'grad_norm': 2.5618298053741455, 'learning_rate': 1.4006410256410257e-05, 'epoch': 1.2}
{'loss': 1.0843, 'grad_norm': 2.546976089477539, 'learning_rate': 1.3605769230769232e-05, 'epoch': 1.28}
{'loss': 1.069, 'grad_norm': 2.9965779781341553, 'learning_rate': 1.3205128205128207e-05, 'epoch': 1.36}
{'loss': 1.1034, 'grad_norm': 3.1490280628204346, 'learning_rate': 1.280448717948718e-05, 'epoch': 1.44}
{'loss': 1.0302, 'grad_norm': 2.51676607131958, 'learning_rate': 1.2403846153846156e-05, 'epoch': 1.52}
{'loss': 1.0903, 'grad_norm': 3.2423384189605713, 'learning_rate': 1.2003205128205129e-05, 'epoch': 1.6}
{'loss': 1.0672, 'grad_norm': 2.541400671005249, 'learning_rate': 1.1602564102564104e-05, 'epoch': 1.68}
{'loss': 1.0729, 'grad_norm': 2.4539122581481934, 'learning_rate': 1.1201923076923078e-05, 'epoch': 1.76}
{'loss': 1.1075, 'grad_norm': 3.0724191665649414, 'learning_rate': 1.0801282051282051e-05, 'epoch': 1.84}
{'loss': 1.0761, 'grad_norm': 2.530017852783203, 'learning_rate': 1.0400641025641028e-05, 'epoch': 1.92}
{'loss': 1.0764, 'grad_norm': 3.1048572063446045, 'learning_rate': 1e-05, 'epoch': 2.0}
{'eval_loss': 1.0735266208648682, 'eval_runtime': 13.0117, 'eval_samples_per_second': 23.056, 'eval_steps_per_second': 11.528, 'epoch': 2.0}
{'loss': 1.0707, 'grad_norm': 2.6790428161621094, 'learning_rate': 9.599358974358976e-06, 'epoch': 2.08}
{'loss': 1.0633, 'grad_norm': 2.4901325702667236, 'learning_rate': 9.198717948717949e-06, 'epoch': 2.16}
{'loss': 1.0353, 'grad_norm': 3.1877198219299316, 'learning_rate': 8.798076923076923e-06, 'epoch': 2.24}
{'loss': 1.0664, 'grad_norm': 2.8914921283721924, 'learning_rate': 8.397435897435898e-06, 'epoch': 2.32}
{'loss': 1.0464, 'grad_norm': 2.4075241088867188, 'learning_rate': 7.996794871794873e-06, 'epoch': 2.4}
{'loss': 1.0776, 'grad_norm': 2.791334390640259, 'learning_rate': 7.5961538461538465e-06, 'epoch': 2.48}
{'loss': 1.057, 'grad_norm': 2.4017550945281982, 'learning_rate': 7.195512820512821e-06, 'epoch': 2.56}
{'loss': 1.0836, 'grad_norm': 2.8666446208953857, 'learning_rate': 6.794871794871796e-06, 'epoch': 2.64}
{'loss': 1.0429, 'grad_norm': 3.366457462310791, 'learning_rate': 6.394230769230769e-06, 'epoch': 2.72}
{'loss': 1.077, 'grad_norm': 3.019592761993408, 'learning_rate': 5.9935897435897436e-06, 'epoch': 2.8}
{'loss': 1.0434, 'grad_norm': 3.8809738159179688, 'learning_rate': 5.592948717948718e-06, 'epoch': 2.88}
{'loss': 1.0106, 'grad_norm': 2.8621859550476074, 'learning_rate': 5.192307692307693e-06, 'epoch': 2.96}
{'eval_loss': 1.0652812719345093, 'eval_runtime': 13.0151, 'eval_samples_per_second': 23.05, 'eval_steps_per_second': 11.525, 'epoch': 3.0}
{'loss': 1.0375, 'grad_norm': 2.9568724632263184, 'learning_rate': 4.791666666666668e-06, 'epoch': 3.04}
{'loss': 1.0619, 'grad_norm': 3.4704372882843018, 'learning_rate': 4.3910256410256415e-06, 'epoch': 3.12}
{'loss': 1.0486, 'grad_norm': 3.6937663555145264, 'learning_rate': 3.990384615384616e-06, 'epoch': 3.2}
{'loss': 1.0536, 'grad_norm': 2.971681833267212, 'learning_rate': 3.58974358974359e-06, 'epoch': 3.28}
{'loss': 1.0, 'grad_norm': 2.5205883979797363, 'learning_rate': 3.1891025641025643e-06, 'epoch': 3.36}
{'loss': 1.0565, 'grad_norm': 3.1745316982269287, 'learning_rate': 2.7884615384615386e-06, 'epoch': 3.44}
{'loss': 1.0258, 'grad_norm': 2.8462510108947754, 'learning_rate': 2.3878205128205133e-06, 'epoch': 3.52}
{'loss': 1.0716, 'grad_norm': 2.803346872329712, 'learning_rate': 1.987179487179487e-06, 'epoch': 3.6}
{'loss': 1.0411, 'grad_norm': 3.902329683303833, 'learning_rate': 1.5865384615384616e-06, 'epoch': 3.68}
{'loss': 1.0426, 'grad_norm': 3.4316060543060303, 'learning_rate': 1.185897435897436e-06, 'epoch': 3.76}
{'loss': 1.021, 'grad_norm': 2.5906147956848145, 'learning_rate': 7.852564102564103e-07, 'epoch': 3.84}
{'loss': 1.0232, 'grad_norm': 2.9005346298217773, 'learning_rate': 3.846153846153847e-07, 'epoch': 3.92}
{'eval_loss': 1.062900185585022, 'eval_runtime': 13.0108, 'eval_samples_per_second': 23.058, 'eval_steps_per_second': 11.529, 'epoch': 3.99}
{'train_runtime': 960.4001, 'train_samples_per_second': 10.412, 'train_steps_per_second': 1.299, 'train_loss': 1.1422627308429816, 'epoch': 3.99}
:) hope it's better now
