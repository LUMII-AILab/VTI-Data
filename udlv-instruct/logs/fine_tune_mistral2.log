TRANSFORMERS_CACHE: /data/transformers_cache
HF_HOME: /data/huggingface
HUGGINGFACE_HUB_CACHE: /data/huggingface/hub
HF_DATASETS_CACHE: /data/hf_datasets_cache
TMPDIR: /data/tmp
Adding a distinct [PAD] token
Input IDs:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073, 131073]
Labels:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
Valid Label Tokens:  [1, 63084, 1314, 1360, 1564, 12624, 6913, 41793, 57629, 1916, 90982, 1864, 55847, 1099, 26176, 1457, 27563, 8571, 1264, 5144, 1403, 5108, 1044, 128292, 5822, 4961, 12491, 1327, 1291, 13681, 4011, 56204, 52317, 7701, 4320, 50913, 3659, 27786, 15137, 115546, 41140, 4547, 1626, 1067, 1318, 103922, 52701, 6690, 51219, 3293, 48196, 6953, 4547, 7173, 26617, 38059, 1049, 1041, 8614, 3695, 94558, 3171, 1112, 44774, 4589, 38059, 1050, 1041, 1457, 32287, 3636, 1386, 1475, 2482, 89309, 19448, 11720, 1288, 4431, 22636, 1836, 1412, 4888, 38059, 1051, 1041, 102853, 6690, 1275, 32287, 1115, 3740, 96888, 26667, 1052, 1456, 1040, 1049, 1041, 9203, 2476, 1513, 88490, 5796, 7701, 53620, 1552, 27786, 1626, 1040, 1050, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1051, 1041, 9203, 2476, 1513, 88490, 45650, 1108, 7701, 17602, 7701, 26829, 1777, 1552, 10128, 2170, 24448, 1288, 1626, 1040, 1052, 1041, 25853, 2392, 6685, 4547, 3190, 1777, 1552, 10128, 1402, 44036, 1046, 131072, 131072]
131072
<|endoftext|>
{'loss': 2.8434, 'grad_norm': 3.6593971252441406, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.08}
{'loss': 1.9422, 'grad_norm': 2.727250099182129, 'learning_rate': 1.842948717948718e-05, 'epoch': 0.16}
{'loss': 1.4661, 'grad_norm': 2.4799206256866455, 'learning_rate': 1.762820512820513e-05, 'epoch': 0.24}
{'loss': 1.3434, 'grad_norm': 2.817880868911743, 'learning_rate': 1.682692307692308e-05, 'epoch': 0.32}
{'loss': 1.2308, 'grad_norm': 2.686633586883545, 'learning_rate': 1.602564102564103e-05, 'epoch': 0.4}
{'loss': 1.2192, 'grad_norm': 2.9680025577545166, 'learning_rate': 1.5224358974358975e-05, 'epoch': 0.48}
{'loss': 1.1988, 'grad_norm': 3.0246551036834717, 'learning_rate': 1.4423076923076924e-05, 'epoch': 0.56}
{'loss': 1.1958, 'grad_norm': 3.582712173461914, 'learning_rate': 1.3621794871794874e-05, 'epoch': 0.64}
{'loss': 1.1653, 'grad_norm': 2.3185226917266846, 'learning_rate': 1.2820512820512823e-05, 'epoch': 0.72}
{'loss': 1.1553, 'grad_norm': 2.5275232791900635, 'learning_rate': 1.201923076923077e-05, 'epoch': 0.8}
{'loss': 1.1313, 'grad_norm': 2.7026164531707764, 'learning_rate': 1.1217948717948719e-05, 'epoch': 0.88}
{'loss': 1.1247, 'grad_norm': 2.838611602783203, 'learning_rate': 1.0416666666666668e-05, 'epoch': 0.96}
{'eval_loss': 1.1029443740844727, 'eval_runtime': 12.998, 'eval_samples_per_second': 23.08, 'eval_steps_per_second': 11.54, 'epoch': 1.0}
{'loss': 1.1056, 'grad_norm': 2.459503412246704, 'learning_rate': 9.615384615384616e-06, 'epoch': 1.04}
{'loss': 1.0815, 'grad_norm': 2.377929210662842, 'learning_rate': 8.814102564102565e-06, 'epoch': 1.12}
{'loss': 1.0884, 'grad_norm': 2.773725986480713, 'learning_rate': 8.012820512820515e-06, 'epoch': 1.2}
{'loss': 1.0918, 'grad_norm': 2.660365104675293, 'learning_rate': 7.211538461538462e-06, 'epoch': 1.28}
{'loss': 1.0773, 'grad_norm': 3.673123359680176, 'learning_rate': 6.410256410256412e-06, 'epoch': 1.36}
{'loss': 1.1128, 'grad_norm': 3.274043083190918, 'learning_rate': 5.608974358974359e-06, 'epoch': 1.44}
{'loss': 1.0384, 'grad_norm': 2.651393413543701, 'learning_rate': 4.807692307692308e-06, 'epoch': 1.52}
{'loss': 1.0989, 'grad_norm': 3.3266360759735107, 'learning_rate': 4.006410256410257e-06, 'epoch': 1.6}
{'loss': 1.0766, 'grad_norm': 2.466571569442749, 'learning_rate': 3.205128205128206e-06, 'epoch': 1.68}
{'loss': 1.0827, 'grad_norm': 2.541335105895996, 'learning_rate': 2.403846153846154e-06, 'epoch': 1.76}
{'loss': 1.1201, 'grad_norm': 3.0145132541656494, 'learning_rate': 1.602564102564103e-06, 'epoch': 1.84}
{'loss': 1.0885, 'grad_norm': 2.4915637969970703, 'learning_rate': 8.012820512820515e-07, 'epoch': 1.92}
{'eval_loss': 1.0865076780319214, 'eval_runtime': 12.9972, 'eval_samples_per_second': 23.082, 'eval_steps_per_second': 11.541, 'epoch': 2.0}
{'train_runtime': 483.4741, 'train_samples_per_second': 10.342, 'train_steps_per_second': 1.291, 'train_loss': 1.2468681396582189, 'epoch': 2.0}
:) hope it's better now
